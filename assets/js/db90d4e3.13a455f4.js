"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5137],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=u(n),d=a,f=m["".concat(s,".").concat(d)]||m[d]||c[d]||i;return n?r.createElement(f,o(o({ref:t},p),{},{components:n})):r.createElement(f,o({ref:t},p))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var u=2;u<i;u++)o[u]=n[u];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8339:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return u},toc:function(){return p},default:function(){return m}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),o=["components"],l={sidebar_label:"tune",title:"tune.tune"},s=void 0,u={unversionedId:"reference/tune/tune",id:"reference/tune/tune",isDocsHomePage:!1,title:"tune.tune",description:"ExperimentAnalysis Objects",source:"@site/docs/reference/tune/tune.md",sourceDirName:"reference/tune",slug:"/reference/tune/tune",permalink:"/FLAML/docs/reference/tune/tune",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/tune/tune.md",tags:[],version:"current",frontMatter:{sidebar_label:"tune",title:"tune.tune"},sidebar:"referenceSideBar",previous:{title:"trial_runner",permalink:"/FLAML/docs/reference/tune/trial_runner"},next:{title:"automl",permalink:"/FLAML/docs/reference/automl"}},p=[{value:"ExperimentAnalysis Objects",id:"experimentanalysis-objects",children:[{value:"report",id:"report",children:[],level:4},{value:"run",id:"run",children:[],level:4}],level:2}],c={toc:p};function m(e){var t=e.components,n=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"experimentanalysis-objects"},"ExperimentAnalysis Objects"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"class ExperimentAnalysis(EA)\n")),(0,i.kt)("p",null,"Class for storing the experiment results."),(0,i.kt)("h4",{id:"report"},"report"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"def report(_metric=None, **kwargs)\n")),(0,i.kt)("p",null,"A function called by the HPO application to report final or intermediate\nresults."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Example"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import time\nfrom flaml import tune\n\ndef compute_with_config(config):\n    current_time = time.time()\n    metric2minimize = (round(config['x'])-95000)**2\n    time2eval = time.time() - current_time\n    tune.report(metric2minimize=metric2minimize, time2eval=time2eval)\n\nanalysis = tune.run(\n    compute_with_config,\n    config={\n        'x': tune.lograndint(lower=1, upper=1000000),\n        'y': tune.randint(lower=1, upper=1000000)\n    },\n    metric='metric2minimize', mode='min',\n    num_samples=1000000, time_budget_s=60, use_ray=False)\n\nprint(analysis.trials[-1].last_result)\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"_metric")," - Optional default anonymous metric for ",(0,i.kt)("inlineCode",{parentName:"li"},"tune.report(value)"),".\n(For compatibility with ray.tune.report)"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"**kwargs")," - Any key value pair to be reported.")),(0,i.kt)("h4",{id:"run"},"run"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"def run(evaluation_function, config: Optional[dict] = None, low_cost_partial_config: Optional[dict] = None, cat_hp_cost: Optional[dict] = None, metric: Optional[str] = None, mode: Optional[str] = None, time_budget_s: Union[int, float] = None, points_to_evaluate: Optional[List[dict]] = None, evaluated_rewards: Optional[List] = None, resource_attr: Optional[str] = None, min_resource: Optional[float] = None, max_resource: Optional[float] = None, reduction_factor: Optional[float] = None, scheduler=None, search_alg=None, verbose: Optional[int] = 2, local_dir: Optional[str] = None, num_samples: Optional[int] = 1, resources_per_trial: Optional[dict] = None, config_constraints: Optional[\n        List[Tuple[Callable[[dict], float], str, float]]\n    ] = None, metric_constraints: Optional[List[Tuple[str, str, float]]] = None, max_failure: Optional[int] = 100, use_ray: Optional[bool] = False, use_incumbent_result_in_evaluation: Optional[bool] = None)\n")),(0,i.kt)("p",null,"The trigger for HPO."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Example"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import time\nfrom flaml import tune\n\ndef compute_with_config(config):\n    current_time = time.time()\n    metric2minimize = (round(config['x'])-95000)**2\n    time2eval = time.time() - current_time\n    tune.report(metric2minimize=metric2minimize, time2eval=time2eval)\n\nanalysis = tune.run(\n    compute_with_config,\n    config={\n        'x': tune.lograndint(lower=1, upper=1000000),\n        'y': tune.randint(lower=1, upper=1000000)\n    },\n    metric='metric2minimize', mode='min',\n    num_samples=-1, time_budget_s=60, use_ray=False)\n\nprint(analysis.trials[-1].last_result)\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"evaluation_function")," - A user-defined evaluation function.\nIt takes a configuration as input, outputs a evaluation\nresult (can be a numerical value or a dictionary of string\nand numerical value pairs) for the input configuration.\nFor machine learning tasks, it usually involves training and\nscoring a machine learning model, e.g., through validation loss."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"config")," - A dictionary to specify the search space."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"low_cost_partial_config")," - A dictionary from a subset of\ncontrolled dimensions to the initial low-cost values.\ne.g., ",(0,i.kt)("inlineCode",{parentName:"li"},"{'n_estimators': 4, 'max_leaves': 4}")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"cat_hp_cost")," - A dictionary from a subset of categorical dimensions\nto the relative cost of each choice.\ne.g., ",(0,i.kt)("inlineCode",{parentName:"li"},"{'tree_method': [1, 1, 2]}"),"\ni.e., the relative cost of the\nthree choices of 'tree_method' is 1, 1 and 2 respectively"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metric")," - A string of the metric name to optimize for."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"mode")," - A string in ","['min', 'max']"," to specify the objective as\nminimization or maximization."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"time_budget_s")," - int or float | The time budget in seconds."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"points_to_evaluate")," - A list of initial hyperparameter\nconfigurations to run first."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"evaluated_rewards")," ",(0,i.kt)("em",{parentName:"li"},"list")," - If you have previously evaluated the\nparameters passed in as points_to_evaluate you can avoid\nre-running those trials by passing in the reward attributes\nas a list so the optimiser can be told the results without\nneeding to re-compute the trial. Must be the same length as\npoints_to_evaluate.\ne.g.,")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'points_to_evaluate = [\n    {"b": .99, "cost_related": {"a": 3}},\n    {"b": .99, "cost_related": {"a": 2}},\n]\nevaluated_rewards=[3.0, 1.0]\n')),(0,i.kt)("p",null,"  means that you know the reward for the two configs in\npoints_to_evaluate are 3.0 and 1.0 respectively and want to\ninform run()."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"resource_attr"),' - A string to specify the resource dimension used by\nthe scheduler via "scheduler".'),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"min_resource")," - A float of the minimal resource to use for the resource_attr."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"max_resource")," - A float of the maximal resource to use for the resource_attr."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"reduction_factor")," - A float of the reduction factor used for incremental\npruning."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"scheduler")," - A scheduler for executing the experiment. Can be None, 'flaml',\n'asha' or a custom instance of the TrialScheduler class. Default is None:\nin this case when resource_attr is provided, the 'flaml' scheduler will be\nused, otherwise no scheduler will be used. When set 'flaml', an\nauthentic scheduler implemented in FLAML will be used. It does not\nrequire users to report intermediate results in evaluation_function.\nFind more details about this scheduler in this paper\n",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1911.04706.pdf"},"https://arxiv.org/pdf/1911.04706.pdf"),').\nWhen set \'asha\', the input for arguments "resource_attr",\n"min_resource", "max_resource" and "reduction_factor" will be passed\nto ASHA\'s "time_attr",  "max_t", "grace_period" and "reduction_factor"\nrespectively. You can also provide a self-defined scheduler instance\nof the TrialScheduler class. When \'asha\' or self-defined scheduler is\nused, you usually need to report intermediate results in the evaluation\nfunction. Please find examples using different types of schedulers\nand how to set up the corresponding evaluation functions in\ntest/tune/test_scheduler.py. TODO: point to notebook examples.'),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"search_alg")," - An instance of BlendSearch as the search algorithm\nto be used. The same instance can be used for iterative tuning.\ne.g.,")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flaml import BlendSearch\nalgo = BlendSearch(metric='val_loss', mode='min',\n        space=search_space,\n        low_cost_partial_config=low_cost_partial_config)\nfor i in range(10):\n    analysis = tune.run(compute_with_config,\n        search_alg=algo, use_ray=False)\n    print(analysis.trials[-1].last_result)\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"verbose")," - 0, 1, 2, or 3. Verbosity mode for ray if ray backend is used.\n0 = silent, 1 = only status updates, 2 = status and brief trial\nresults, 3 = status and detailed trial results. Defaults to 2.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"local_dir")," - A string of the local dir to save ray logs if ray backend is\nused; or a local dir to save the tuning log.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"num_samples")," - An integer of the number of configs to try. Defaults to 1.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"resources_per_trial")," - A dictionary of the hardware resources to allocate\nper trial, e.g., ",(0,i.kt)("inlineCode",{parentName:"p"},"{'cpu': 1}"),". It is only valid when using ray backend\n(by setting 'use_ray = True'). It shall be used when you need to do\n",(0,i.kt)("a",{parentName:"p",href:"https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function#parallel-tuning"},"parallel tuning"),".")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"config_constraints")," - A list of config constraints to be satisfied.\ne.g., ",(0,i.kt)("inlineCode",{parentName:"p"},"config_constraints = [(mem_size, '<=', 1024**3)]")),(0,i.kt)("p",{parentName:"li"},"mem_size is a function which produces a float number for the bytes\nneeded for a config.\nIt is used to skip configs which do not fit in memory.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"metric_constraints")," - A list of metric constraints to be satisfied.\ne.g., ",(0,i.kt)("inlineCode",{parentName:"p"},"['precision', '>=', 0.9]"),'. The sign can be ">=" or "<=".')),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"max_failure")," - int | the maximal consecutive number of failures to sample\na trial before the tuning is terminated.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"use_ray")," - A boolean of whether to use ray as the backend."))))}m.isMDXComponent=!0}}]);