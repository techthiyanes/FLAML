"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5251],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>d});var a=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var p=a.createContext({}),c=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=c(e.components);return a.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,r=e.originalType,p=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),u=c(n),d=l,k=u["".concat(p,".").concat(d)]||u[d]||m[d]||r;return n?a.createElement(k,i(i({ref:t},s),{},{components:n})):a.createElement(k,i({ref:t},s))}));function d(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=n.length,i=new Array(r);i[0]=u;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:l,i[1]=o;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},1535:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>i,default:()=>s,frontMatter:()=>r,metadata:()=>o,toc:()=>p});var a=n(7462),l=(n(7294),n(3905));const r={sidebar_label:"completion",title:"integrations.oai.completion"},i=void 0,o={unversionedId:"reference/integrations/oai/completion",id:"reference/integrations/oai/completion",isDocsHomePage:!1,title:"integrations.oai.completion",description:"get\\_key",source:"@site/docs/reference/integrations/oai/completion.md",sourceDirName:"reference/integrations/oai",slug:"/reference/integrations/oai/completion",permalink:"/FLAML/docs/reference/integrations/oai/completion",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/integrations/oai/completion.md",tags:[],version:"current",frontMatter:{sidebar_label:"completion",title:"integrations.oai.completion"},sidebar:"referenceSideBar",previous:{title:"suggest",permalink:"/FLAML/docs/reference/default/suggest"},next:{title:"autovw",permalink:"/FLAML/docs/reference/onlineml/autovw"}},p=[{value:"get_key",id:"get_key",children:[],level:4},{value:"Completion Objects",id:"completion-objects",children:[{value:"set_cache",id:"set_cache",children:[],level:4},{value:"eval",id:"eval",children:[],level:4},{value:"tune",id:"tune",children:[],level:4},{value:"create",id:"create",children:[],level:4}],level:2}],c={toc:p};function s(e){let{components:t,...n}=e;return(0,l.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h4",{id:"get_key"},"get","_","key"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def get_key(config)\n")),(0,l.kt)("p",null,"Get a unique identifier of a configuration."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"config")," ",(0,l.kt)("em",{parentName:"li"},"dict or list")," - A configuration.")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Returns"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"tuple")," - A unique identifier which can be used as a key for a dict.")),(0,l.kt)("h2",{id:"completion-objects"},"Completion Objects"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"class Completion()\n")),(0,l.kt)("p",null,"A class for OpenAI API completion."),(0,l.kt)("h4",{id:"set_cache"},"set","_","cache"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'@classmethod\ndef set_cache(cls, seed=41, cache_path=".cache")\n')),(0,l.kt)("p",null,"Set cache path."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"seed")," ",(0,l.kt)("em",{parentName:"li"},"int, Optional")," - The integer identifier for the pseudo seed.\nResults corresponding to different seeds will be cached in different places."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"cache_path")," ",(0,l.kt)("em",{parentName:"li"},"str, Optional")," - The root path for the cache.\nThe complete cache path will be {cache_path}/{seed}.")),(0,l.kt)("h4",{id:"eval"},"eval"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@classmethod\ndef eval(cls, config: dict, prune=True, eval_only=False)\n")),(0,l.kt)("p",null,"Evaluate the given config as the hyperparameter setting for the openai api call."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"config")," ",(0,l.kt)("em",{parentName:"li"},"dict")," - Hyperparameter setting for the openai api call."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"prune")," ",(0,l.kt)("em",{parentName:"li"},"bool, optional")," - Whether to enable pruning. Defaults to True."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"eval_only")," ",(0,l.kt)("em",{parentName:"li"},"bool, optional")," - Whether to evaluate only. Defaults to False.")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Returns"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"dict")," - Evaluation results.")),(0,l.kt)("h4",{id:"tune"},"tune"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@classmethod\ndef tune(cls, data, metric, mode, eval_func, log_file_name=None, inference_budget=None, optimization_budget=None, num_samples=1, **config, ,)\n")),(0,l.kt)("p",null,"Tune the parameters for the OpenAI API call."),(0,l.kt)("p",null,"TODO: support parallel tuning with ray or spark."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"data")," ",(0,l.kt)("em",{parentName:"li"},"list")," - The list of data points."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"metric")," ",(0,l.kt)("em",{parentName:"li"},"str")," - The metric to optimize."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"mode")," ",(0,l.kt)("em",{parentName:"li"},"str"),' - The optimization mode, "min" or "max.'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"eval_func")," ",(0,l.kt)("em",{parentName:"li"},"Callable")," - The evaluation function for responses."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"log_file_name")," ",(0,l.kt)("em",{parentName:"li"},"str, optional")," - The log file."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"inference_budget")," ",(0,l.kt)("em",{parentName:"li"},"float, optional")," - The inference budget."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"optimization_budget")," ",(0,l.kt)("em",{parentName:"li"},"float, optional")," - The optimization budget."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"num_samples")," ",(0,l.kt)("em",{parentName:"li"},"int, optional")," - The number of samples to evaluate."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"**config")," ",(0,l.kt)("em",{parentName:"li"},"dict")," - The search space to update over the default search.\nFor prompt, please provide a string or a list of strings.\nFor stop, please provide a string, a list of strings, or a list of lists of strings.")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Returns"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"dict")," - The optimized hyperparameter setting."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"tune.ExperimentAnalysis")," - The tuning results.")),(0,l.kt)("h4",{id:"create"},"create"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@classmethod\ndef create(cls, context, use_cache=True, **config)\n")),(0,l.kt)("p",null,"Make a completion for a given context."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"context")," ",(0,l.kt)("em",{parentName:"li"},"dict")," - The context to instantiate the prompt.\nIt needs to contain keys that are used by the prompt template.\nE.g., ",(0,l.kt)("inlineCode",{parentName:"li"},'prompt="Complete the following sentence: {prefix}"'),"."),(0,l.kt)("li",{parentName:"ul"},"`",(0,l.kt)("inlineCode",{parentName:"li"},'context={"prefix"'),' - "Today I feel"}`.\nThe actual prompt sent to OpenAI will be:\n"Complete the following sentence: Today I feel".'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"use_cache")," ",(0,l.kt)("em",{parentName:"li"},"bool, Optional")," - Whether to use cached responses.")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Returns"),":"),(0,l.kt)("p",null,"  Responses from OpenAI API."))}s.isMDXComponent=!0}}]);