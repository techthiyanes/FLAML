"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3919],{3905:(e,t,r)=>{r.d(t,{Zo:()=>f,kt:()=>d});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var c=n.createContext({}),u=function(e){var t=n.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},f=function(e){var t=u(e.components);return n.createElement(c.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},s=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,f=l(e,["components","mdxType","originalType","parentName"]),s=u(r),d=o,m=s["".concat(c,".").concat(d)]||s[d]||p[d]||a;return r?n.createElement(m,i(i({ref:t},f),{},{components:r})):n.createElement(m,i({ref:t},f))}));function d(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=s;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var u=2;u<a;u++)i[u]=r[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}s.displayName="MDXCreateElement"},6547:(e,t,r)=>{r.r(t),r.d(t,{contentTitle:()=>i,default:()=>f,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var n=r(7462),o=(r(7294),r(3905));const a={sidebar_label:"greedy",title:"default.greedy"},i=void 0,l={unversionedId:"reference/default/greedy",id:"reference/default/greedy",isDocsHomePage:!1,title:"default.greedy",description:"construct\\_portfolio",source:"@site/docs/reference/default/greedy.md",sourceDirName:"reference/default",slug:"/reference/default/greedy",permalink:"/FLAML/docs/reference/default/greedy",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/default/greedy.md",tags:[],version:"current",frontMatter:{sidebar_label:"greedy",title:"default.greedy"},sidebar:"referenceSideBar",previous:{title:"estimator",permalink:"/FLAML/docs/reference/default/estimator"},next:{title:"portfolio",permalink:"/FLAML/docs/reference/default/portfolio"}},c=[{value:"construct_portfolio",id:"construct_portfolio",children:[],level:4}],u={toc:c};function f(e){let{components:t,...r}=e;return(0,o.kt)("wrapper",(0,n.Z)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h4",{id:"construct_portfolio"},"construct","_","portfolio"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"def construct_portfolio(regret_matrix, meta_features, regret_bound)\n")),(0,o.kt)("p",null,"The portfolio construction algorithm."),(0,o.kt)("p",null,"Reference: ",(0,o.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2202.09927"},"Mining Robust Default Configurations for Resource-constrained AutoML"),"."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Arguments"),":"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"regret_matrix")," - A dataframe of regret matrix."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"meta_features")," - None or a dataframe of metafeatures matrix.\nWhen set to None, the algorithm uses greedy strategy.\nOtherwise, the algorithm uses greedy strategy with feedback\nfrom the nearest neighbor predictor."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"regret_bound")," - A float of the regret bound.")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Returns"),":"),(0,o.kt)("p",null,"  A list of configuration names."))}f.isMDXComponent=!0}}]);