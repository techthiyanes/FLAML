"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4288],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return d}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=p(a),d=o,f=m["".concat(l,".").concat(d)]||m[d]||u[d]||r;return a?n.createElement(f,i(i({ref:t},c),{},{components:a})):n.createElement(f,i({ref:t},c))}));function d(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},3581:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return p},toc:function(){return c},default:function(){return m}});var n=a(7462),o=a(3366),r=(a(7294),a(3905)),i=["components"],s={},l="Frequently Asked Questions",p={unversionedId:"FAQ",id:"FAQ",isDocsHomePage:!1,title:"Frequently Asked Questions",description:"About lowcostpartial_config in tune.",source:"@site/docs/FAQ.md",sourceDirName:".",slug:"/FAQ",permalink:"/FLAML/docs/FAQ",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/FAQ.md",tags:[],version:"current",frontMatter:{}},c=[{value:"About <code>low_cost_partial_config</code> in <code>tune</code>.",id:"about-low_cost_partial_config-in-tune",children:[],level:3},{value:"How does FLAML handle imbalanced data (unequal distribution of target classes in classification task)?",id:"how-does-flaml-handle-imbalanced-data-unequal-distribution-of-target-classes-in-classification-task",children:[],level:3},{value:"How to interpret model performance? Is it possible for me to visualize feature importance, SHAP values, optimization history?",id:"how-to-interpret-model-performance-is-it-possible-for-me-to-visualize-feature-importance-shap-values-optimization-history",children:[],level:3}],u={toc:c};function m(e){var t=e.components,a=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"frequently-asked-questions"},"Frequently Asked Questions"),(0,r.kt)("h3",{id:"about-low_cost_partial_config-in-tune"},"About ",(0,r.kt)("inlineCode",{parentName:"h3"},"low_cost_partial_config")," in ",(0,r.kt)("inlineCode",{parentName:"h3"},"tune"),"."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Definition and purpose: The ",(0,r.kt)("inlineCode",{parentName:"p"},"low_cost_partial_config")," is a dictionary of subset of the hyperparameter coordinates whose value corresponds to a configuration with known low-cost (i.e., low computation cost for training the corresponding model).  The concept of low/high-cost is meaningful in the case where a subset of the hyperparameters to tune directly affects the computation cost for training the model. For example, ",(0,r.kt)("inlineCode",{parentName:"p"},"n_estimators")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"max_leaves")," are known to affect the training cost of tree-based learners. We call this subset of hyperparameters, ",(0,r.kt)("em",{parentName:"p"},"cost-related hyperparameters"),". In such scenarios, if you are aware of low-cost configurations for the cost-related hyperparameters, you are recommended to set them as the ",(0,r.kt)("inlineCode",{parentName:"p"},"low_cost_partial_config"),". Using the tree-based method example again, since we know that small ",(0,r.kt)("inlineCode",{parentName:"p"},"n_estimators")," and  ",(0,r.kt)("inlineCode",{parentName:"p"},"max_leaves")," generally correspond to simpler models and thus lower cost, we set ",(0,r.kt)("inlineCode",{parentName:"p"},"{'n_estimators': 4, 'max_leaves': 4}")," as the ",(0,r.kt)("inlineCode",{parentName:"p"},"low_cost_partial_config")," by default (note that ",(0,r.kt)("inlineCode",{parentName:"p"},"4")," is the lower bound of search space for these two hyperparameters), e.g., in ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/microsoft/FLAML/blob/main/flaml/model.py#L215"},"LGBM"),".  Configuring ",(0,r.kt)("inlineCode",{parentName:"p"},"low_cost_partial_config")," helps the search algorithms make more cost-efficient choices.",(0,r.kt)("br",{parentName:"p"}),"\n","In AutoML, the ",(0,r.kt)("inlineCode",{parentName:"p"},"low_cost_init_value")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"search_space()")," function for each estimator serves the same role.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Usage in practice: It is recommended to configure it if there are cost-related hyperparameters in your tuning task and you happen to know the low-cost values for them, but it is not required( It is fine to leave it the default value, i.e., ",(0,r.kt)("inlineCode",{parentName:"p"},"None"),").")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"How does it work: ",(0,r.kt)("inlineCode",{parentName:"p"},"low_cost_partial_config")," if configured, will be used as an initial point of the search. It also affects the search trajectory. For more details about how does it play a role in the search algorithms, please refer to the papers about the search algorithms used: Section 2 of ",(0,r.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2005.01571.pdf"},"Frugal Optimization for Cost-related Hyperparameters (CFO)")," and Section 3 of ",(0,r.kt)("a",{parentName:"p",href:"https://openreview.net/pdf?id=VbLH04pRA3"},"Economical Hyperparameter Optimization with Blended Search Strategy (BlendSearch)"),"."))),(0,r.kt)("h3",{id:"how-does-flaml-handle-imbalanced-data-unequal-distribution-of-target-classes-in-classification-task"},"How does FLAML handle imbalanced data (unequal distribution of target classes in classification task)?"),(0,r.kt)("p",null,"Currently FLAML does several things for imbalanced data."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"When a class contains fewer than 20 examples, we repeatedly add these examples to the training data until the count is at least 20."),(0,r.kt)("li",{parentName:"ol"},"We use stratified sampling when doing holdout and kf."),(0,r.kt)("li",{parentName:"ol"},"We make sure no class is empty in both training and holdout data."),(0,r.kt)("li",{parentName:"ol"},"We allow users to pass ",(0,r.kt)("inlineCode",{parentName:"li"},"sample_weight")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"AutoML.fit()"),".")),(0,r.kt)("h3",{id:"how-to-interpret-model-performance-is-it-possible-for-me-to-visualize-feature-importance-shap-values-optimization-history"},"How to interpret model performance? Is it possible for me to visualize feature importance, SHAP values, optimization history?"),(0,r.kt)("p",null,"You can use ",(0,r.kt)("inlineCode",{parentName:"p"},"automl.model.estimator.feature_importances_")," to get the ",(0,r.kt)("inlineCode",{parentName:"p"},"feature_importances_")," for the best model found by automl. See an ",(0,r.kt)("a",{parentName:"p",href:"Examples/AutoML-for-XGBoost#plot-feature-importance"},"example"),"."),(0,r.kt)("p",null,"Packages such as ",(0,r.kt)("inlineCode",{parentName:"p"},"azureml-interpret")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"sklearn.inspection.permutation_importance")," can be used on ",(0,r.kt)("inlineCode",{parentName:"p"},"automl.model.estimator")," to explain the selected model.\nModel explanation is frequently asked and adding a native support may be a good feature. Suggestions/contributions are welcome."),(0,r.kt)("p",null,"Optimization history can be checked from the ",(0,r.kt)("a",{parentName:"p",href:"Use-Cases/Task-Oriented-AutoML#log-the-trials"},"log"),". You can also ",(0,r.kt)("a",{parentName:"p",href:"Use-Cases/Task-Oriented-AutoML#plot-learning-curve"},"retrieve the log and plot the learning curve"),"."))}m.isMDXComponent=!0}}]);