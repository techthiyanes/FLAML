"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4364],{3905:function(t,e,r){r.d(e,{Zo:function(){return b},kt:function(){return g}});var a=r(7294);function l(t,e,r){return e in t?Object.defineProperty(t,e,{value:r,enumerable:!0,configurable:!0,writable:!0}):t[e]=r,t}function s(t,e){var r=Object.keys(t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),r.push.apply(r,a)}return r}function o(t){for(var e=1;e<arguments.length;e++){var r=null!=arguments[e]?arguments[e]:{};e%2?s(Object(r),!0).forEach((function(e){l(t,e,r[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(r,e))}))}return t}function m(t,e){if(null==t)return{};var r,a,l=function(t,e){if(null==t)return{};var r,a,l={},s=Object.keys(t);for(a=0;a<s.length;a++)r=s[a],e.indexOf(r)>=0||(l[r]=t[r]);return l}(t,e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(t);for(a=0;a<s.length;a++)r=s[a],e.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(t,r)&&(l[r]=t[r])}return l}var n=a.createContext({}),i=function(t){var e=a.useContext(n),r=e;return t&&(r="function"==typeof t?t(e):o(o({},e),t)),r},b=function(t){var e=i(t.components);return a.createElement(n.Provider,{value:e},t.children)},u={inlineCode:"code",wrapper:function(t){var e=t.children;return a.createElement(a.Fragment,{},e)}},f=a.forwardRef((function(t,e){var r=t.components,l=t.mdxType,s=t.originalType,n=t.parentName,b=m(t,["components","mdxType","originalType","parentName"]),f=i(r),g=l,p=f["".concat(n,".").concat(g)]||f[g]||u[g]||s;return r?a.createElement(p,o(o({ref:e},b),{},{components:r})):a.createElement(p,o({ref:e},b))}));function g(t,e){var r=arguments,l=e&&e.mdxType;if("string"==typeof t||l){var s=r.length,o=new Array(s);o[0]=f;var m={};for(var n in e)hasOwnProperty.call(e,n)&&(m[n]=e[n]);m.originalType=t,m.mdxType="string"==typeof t?t:l,o[1]=m;for(var i=2;i<s;i++)o[i]=r[i];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}f.displayName="MDXCreateElement"},7308:function(t,e,r){r.r(e),r.d(e,{frontMatter:function(){return m},contentTitle:function(){return n},metadata:function(){return i},toc:function(){return b},default:function(){return f}});var a=r(7462),l=r(3366),s=(r(7294),r(3905)),o=["components"],m={},n="AutoML - Time Series Forecast",i={unversionedId:"Examples/AutoML-Time series forecast",id:"Examples/AutoML-Time series forecast",isDocsHomePage:!1,title:"AutoML - Time Series Forecast",description:"Prerequisites",source:"@site/docs/Examples/AutoML-Time series forecast.md",sourceDirName:"Examples",slug:"/Examples/AutoML-Time series forecast",permalink:"/FLAML/docs/Examples/AutoML-Time series forecast",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/Examples/AutoML-Time series forecast.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"AutoML - Regression",permalink:"/FLAML/docs/Examples/AutoML-Regression"},next:{title:"AutoML for LightGBM",permalink:"/FLAML/docs/Examples/AutoML-for-LightGBM"}},b=[{value:"Prerequisites",id:"prerequisites",children:[],level:3},{value:"Simple NumPy Example",id:"simple-numpy-example",children:[{value:"Sample output",id:"sample-output",children:[],level:4}],level:3},{value:"Univariate time series",id:"univariate-time-series",children:[{value:"Sample output",id:"sample-output-1",children:[],level:4},{value:"Compute and plot predictions",id:"compute-and-plot-predictions",children:[],level:4}],level:3},{value:"Multivariate Time Series (Forecasting with Exogeneous Variables)",id:"multivariate-time-series-forecasting-with-exogeneous-variables",children:[{value:"Sample Output",id:"sample-output-2",children:[],level:4}],level:3},{value:"Forecasting Discrete Variables",id:"forecasting-discrete-variables",children:[{value:"Sample Output",id:"sample-output-3",children:[],level:4}],level:3}],u={toc:b};function f(t){var e=t.components,m=(0,l.Z)(t,o);return(0,s.kt)("wrapper",(0,a.Z)({},u,m,{components:e,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"automl---time-series-forecast"},"AutoML - Time Series Forecast"),(0,s.kt)("h3",{id:"prerequisites"},"Prerequisites"),(0,s.kt)("p",null,"Install the ","[ts_forecast]"," option."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'pip install "flaml[ts_forecast]"\n')),(0,s.kt)("h3",{id:"simple-numpy-example"},"Simple NumPy Example"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\nfrom flaml import AutoML\n\nX_train = np.arange('2014-01', '2022-01', dtype='datetime64[M]')\ny_train = np.random.random(size=84)\nautoml = AutoML()\nautoml.fit(X_train=X_train[:84],  # a single column of timestamp\n           y_train=y_train,  # value for each timestamp\n           period=12,  # time horizon to forecast, e.g., 12 months\n           task='ts_forecast', time_budget=15,  # time budget in seconds\n           log_file_name=\"ts_forecast.log\",\n           eval_method=\"holdout\",\n          )\nprint(automl.predict(X_train[84:]))\n")),(0,s.kt)("h4",{id:"sample-output"},"Sample output"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"[flaml.automl: 01-21 08:01:20] {2018} INFO - task = ts_forecast\n[flaml.automl: 01-21 08:01:20] {2020} INFO - Data split method: time\n[flaml.automl: 01-21 08:01:20] {2024} INFO - Evaluation method: holdout\n[flaml.automl: 01-21 08:01:20] {2124} INFO - Minimizing error metric: mape\n[flaml.automl: 01-21 08:01:21] {2181} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'prophet', 'arima', 'sarimax']\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 0, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2547} INFO - Estimated sufficient time budget=1429s. Estimated necessary time budget=1s.\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 0.9s,  estimator lgbm's best error=0.9811,     best estimator lgbm's best error=0.9811\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 1, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 0.9s,  estimator lgbm's best error=0.9811,     best estimator lgbm's best error=0.9811\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 2, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 0.9s,  estimator lgbm's best error=0.9811,     best estimator lgbm's best error=0.9811\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 3, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.9811,     best estimator lgbm's best error=0.9811\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 4, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.9811,     best estimator lgbm's best error=0.9811\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 5, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.9811,     best estimator lgbm's best error=0.9811\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 6, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.9652,     best estimator lgbm's best error=0.9652\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 7, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 8, current learner lgbm\n[flaml.automl: 01-21 08:01:21] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:21] {2434} INFO - iteration 9, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 10, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 11, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 12, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 13, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 14, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 15, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.2s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 16, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.2s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 17, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.2s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 18, current learner rf\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.2s,  estimator rf's best error=1.0994,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 19, current learner rf\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.2s,  estimator rf's best error=1.0848,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 20, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.3s,  estimator xgboost's best error=1.0271,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 21, current learner rf\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.3s,  estimator rf's best error=1.0848,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 22, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.3s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 23, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.3s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 24, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.3s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 25, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.3s,  estimator extra_tree's best error=1.0130,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 26, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.4s,  estimator extra_tree's best error=1.0130,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 27, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.4s,  estimator extra_tree's best error=1.0130,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 28, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.4s,  estimator extra_tree's best error=1.0130,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 29, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.4s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 30, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.5s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 31, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.5s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 32, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.5s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 33, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.5s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 34, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.5s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 35, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.5s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 36, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.6s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 37, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.6s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 38, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.6s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 39, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.6s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 40, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.6s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 41, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.7s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 42, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.7s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 43, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.7s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 44, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.7s,  estimator xgb_limitdepth's best error=1.5815,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 45, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.8s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 46, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.8s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 47, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.8s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 48, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.9s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 49, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.9s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 50, current learner extra_tree\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.9s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 51, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 1.9s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 52, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 2.0s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 53, current learner xgboost\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 2.0s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 54, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 2.0s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 55, current learner lgbm\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 2.0s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 56, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 2.0s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 57, current learner rf\n[flaml.automl: 01-21 08:01:22] {2594} INFO -  at 2.0s,  estimator rf's best error=1.0848,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:22] {2434} INFO - iteration 58, current learner xgboost\n[flaml.automl: 01-21 08:01:23] {2594} INFO -  at 2.1s,  estimator xgboost's best error=1.0015,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:23] {2434} INFO - iteration 59, current learner extra_tree\n[flaml.automl: 01-21 08:01:23] {2594} INFO -  at 2.1s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:23] {2434} INFO - iteration 60, current learner lgbm\n[flaml.automl: 01-21 08:01:23] {2594} INFO -  at 2.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:23] {2434} INFO - iteration 61, current learner extra_tree\n[flaml.automl: 01-21 08:01:23] {2594} INFO -  at 2.1s,  estimator extra_tree's best error=0.9499,       best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:23] {2434} INFO - iteration 62, current learner lgbm\n[flaml.automl: 01-21 08:01:23] {2594} INFO -  at 2.1s,  estimator lgbm's best error=0.9466,     best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:23] {2434} INFO - iteration 63, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:23] {2594} INFO -  at 2.2s,  estimator xgb_limitdepth's best error=0.9683,   best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:23] {2434} INFO - iteration 64, current learner prophet\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.2s,  estimator prophet's best error=1.5706,  best estimator lgbm's best error=0.9466\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 65, current learner arima\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.2s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 66, current learner arima\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.4s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 67, current learner sarimax\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.4s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 68, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.5s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 69, current learner sarimax\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.6s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 70, current learner sarimax\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.6s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 71, current learner arima\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.6s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 72, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.6s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 73, current learner arima\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.7s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 74, current learner sarimax\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.7s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 75, current learner arima\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.8s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 76, current learner sarimax\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 4.9s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 77, current learner arima\n[flaml.automl: 01-21 08:01:25] {2594} INFO -  at 5.0s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:25] {2434} INFO - iteration 78, current learner sarimax\n[flaml.automl: 01-21 08:01:26] {2594} INFO -  at 5.1s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:26] {2434} INFO - iteration 79, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:26] {2594} INFO -  at 5.1s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:26] {2434} INFO - iteration 80, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:26] {2594} INFO -  at 5.1s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:26] {2434} INFO - iteration 81, current learner sarimax\n[flaml.automl: 01-21 08:01:26] {2594} INFO -  at 5.1s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:26] {2434} INFO - iteration 82, current learner prophet\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.6s,  estimator prophet's best error=1.4076,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 83, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.6s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 84, current learner sarimax\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.6s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 85, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.6s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 86, current learner sarimax\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.8s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 87, current learner arima\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.8s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 88, current learner sarimax\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.9s,  estimator sarimax's best error=0.5693,  best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 89, current learner arima\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 6.9s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 90, current learner arima\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 7.0s,  estimator arima's best error=0.5693,    best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 91, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 7.0s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 92, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:27] {2594} INFO -  at 7.0s,  estimator xgb_limitdepth's best error=0.9683,   best estimator arima's best error=0.5693\n[flaml.automl: 01-21 08:01:27] {2434} INFO - iteration 93, current learner sarimax\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.0s,  estimator sarimax's best error=0.5600,  best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 94, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.1s,  estimator xgb_limitdepth's best error=0.9683,   best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 95, current learner sarimax\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.2s,  estimator sarimax's best error=0.5600,  best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 96, current learner arima\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.2s,  estimator arima's best error=0.5693,    best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 97, current learner arima\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.2s,  estimator arima's best error=0.5693,    best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 98, current learner extra_tree\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.3s,  estimator extra_tree's best error=0.9499,       best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 99, current learner sarimax\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.3s,  estimator sarimax's best error=0.5600,  best estimator sarimax's best error=0.5600\n[flaml.automl: 01-21 08:01:28] {2434} INFO - iteration 100, current learner xgb_limitdepth\n[flaml.automl: 01-21 08:01:28] {2594} INFO -  at 7.3s,  estimator xgb_limitdepth's best error=0.9683,   best estimator sarimax's best error=0.5600\n")),(0,s.kt)("h3",{id:"univariate-time-series"},"Univariate time series"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import statsmodels.api as sm\n\ndata = sm.datasets.co2.load_pandas().data\n# data is given in weeks, but the task is to predict monthly, so use monthly averages instead\ndata = data['co2'].resample('MS').mean()\ndata = data.bfill().ffill()  # makes sure there are no missing values\ndata = data.to_frame().reset_index()\nnum_samples = data.shape[0]\ntime_horizon = 12\nsplit_idx = num_samples - time_horizon\ntrain_df = data[:split_idx]  # train_df is a dataframe with two columns: timestamp and label\nX_test = data[split_idx:]['index'].to_frame()  # X_test is a dataframe with dates for prediction\ny_test = data[split_idx:]['co2']  # y_test is a series of the values corresponding to the dates for prediction\n\nfrom flaml import AutoML\n\nautoml = AutoML()\nsettings = {\n    \"time_budget\": 10,  # total running time in seconds\n    \"metric\": 'mape',  # primary metric for validation: 'mape' is generally used for forecast tasks\n    \"task\": 'ts_forecast',  # task type\n    \"log_file_name\": 'CO2_forecast.log',  # flaml log file\n    \"eval_method\": \"holdout\",  # validation method can be chosen from ['auto', 'holdout', 'cv']\n    \"seed\": 7654321,  # random seed\n}\n\nautoml.fit(dataframe=train_df,  # training data\n           label='co2',  # label column\n           period=time_horizon,  # key word argument 'period' must be included for forecast task)\n           **settings)\n")),(0,s.kt)("h4",{id:"sample-output-1"},"Sample output"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"[flaml.automl: 01-21 07:54:04] {2018} INFO - task = ts_forecast\n[flaml.automl: 01-21 07:54:04] {2020} INFO - Data split method: time\n[flaml.automl: 01-21 07:54:04] {2024} INFO - Evaluation method: holdout\n[flaml.automl: 01-21 07:54:04] {2124} INFO - Minimizing error metric: mape\nImporting plotly failed. Interactive plots will not work.\n[flaml.automl: 01-21 07:54:04] {2181} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'prophet', 'arima', 'sarimax']\n[flaml.automl: 01-21 07:54:04] {2434} INFO - iteration 0, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2547} INFO - Estimated sufficient time budget=2145s. Estimated necessary time budget=2s.\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 0.9s,  estimator lgbm's best error=0.0621,     best estimator lgbm's best error=0.0621\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 1, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.0574,     best estimator lgbm's best error=0.0574\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 2, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.0464,     best estimator lgbm's best error=0.0464\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 3, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.0464,     best estimator lgbm's best error=0.0464\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 4, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.0s,  estimator lgbm's best error=0.0365,     best estimator lgbm's best error=0.0365\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 5, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.0192,     best estimator lgbm's best error=0.0192\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 6, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.0192,     best estimator lgbm's best error=0.0192\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 7, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.1s,  estimator lgbm's best error=0.0192,     best estimator lgbm's best error=0.0192\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 8, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.2s,  estimator lgbm's best error=0.0110,     best estimator lgbm's best error=0.0110\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 9, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.2s,  estimator lgbm's best error=0.0110,     best estimator lgbm's best error=0.0110\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 10, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.2s,  estimator lgbm's best error=0.0036,     best estimator lgbm's best error=0.0036\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 11, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.4s,  estimator lgbm's best error=0.0023,     best estimator lgbm's best error=0.0023\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 12, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.4s,  estimator lgbm's best error=0.0023,     best estimator lgbm's best error=0.0023\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 13, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.5s,  estimator lgbm's best error=0.0021,     best estimator lgbm's best error=0.0021\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 14, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.6s,  estimator lgbm's best error=0.0021,     best estimator lgbm's best error=0.0021\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 15, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.7s,  estimator lgbm's best error=0.0020,     best estimator lgbm's best error=0.0020\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 16, current learner lgbm\n[flaml.automl: 01-21 07:54:05] {2594} INFO -  at 1.8s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:05] {2434} INFO - iteration 17, current learner lgbm\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 1.9s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 18, current learner lgbm\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.0s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 19, current learner lgbm\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.1s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 20, current learner rf\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.1s,  estimator rf's best error=0.0228,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 21, current learner rf\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.1s,  estimator rf's best error=0.0210,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 22, current learner xgboost\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.2s,  estimator xgboost's best error=0.6738,  best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 23, current learner xgboost\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.2s,  estimator xgboost's best error=0.6738,  best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 24, current learner xgboost\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.2s,  estimator xgboost's best error=0.1717,  best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 25, current learner xgboost\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.3s,  estimator xgboost's best error=0.0249,  best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 26, current learner xgboost\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.3s,  estimator xgboost's best error=0.0249,  best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 27, current learner xgboost\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.3s,  estimator xgboost's best error=0.0242,  best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 28, current learner extra_tree\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.4s,  estimator extra_tree's best error=0.0245,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 29, current learner extra_tree\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.4s,  estimator extra_tree's best error=0.0160,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 30, current learner lgbm\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.5s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 31, current learner lgbm\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.6s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 32, current learner rf\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.6s,  estimator rf's best error=0.0210,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 33, current learner extra_tree\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.6s,  estimator extra_tree's best error=0.0160,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 34, current learner lgbm\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.8s,  estimator lgbm's best error=0.0017,     best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 35, current learner extra_tree\n[flaml.automl: 01-21 07:54:06] {2594} INFO -  at 2.8s,  estimator extra_tree's best error=0.0158,       best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:06] {2434} INFO - iteration 36, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 2.8s,  estimator xgb_limitdepth's best error=0.0447,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 37, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 2.9s,  estimator xgb_limitdepth's best error=0.0447,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 38, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 2.9s,  estimator xgb_limitdepth's best error=0.0029,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 39, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 3.0s,  estimator xgb_limitdepth's best error=0.0018,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 40, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 3.1s,  estimator xgb_limitdepth's best error=0.0018,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 41, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 3.1s,  estimator xgb_limitdepth's best error=0.0018,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 42, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:07] {2594} INFO -  at 3.3s,  estimator xgb_limitdepth's best error=0.0018,   best estimator lgbm's best error=0.0017\n[flaml.automl: 01-21 07:54:07] {2434} INFO - iteration 43, current learner prophet\n[flaml.automl: 01-21 07:54:09] {2594} INFO -  at 5.5s,  estimator prophet's best error=0.0008,  best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:09] {2434} INFO - iteration 44, current learner arima\n[flaml.automl: 01-21 07:54:10] {2594} INFO -  at 6.1s,  estimator arima's best error=0.0047,    best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:10] {2434} INFO - iteration 45, current learner sarimax\n[flaml.automl: 01-21 07:54:10] {2594} INFO -  at 6.4s,  estimator sarimax's best error=0.0047,  best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:10] {2434} INFO - iteration 46, current learner lgbm\n[flaml.automl: 01-21 07:54:10] {2594} INFO -  at 6.5s,  estimator lgbm's best error=0.0017,     best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:10] {2434} INFO - iteration 47, current learner sarimax\n[flaml.automl: 01-21 07:54:10] {2594} INFO -  at 6.6s,  estimator sarimax's best error=0.0047,  best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:10] {2434} INFO - iteration 48, current learner sarimax\n[flaml.automl: 01-21 07:54:11] {2594} INFO -  at 6.9s,  estimator sarimax's best error=0.0047,  best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:11] {2434} INFO - iteration 49, current learner arima\n[flaml.automl: 01-21 07:54:11] {2594} INFO -  at 6.9s,  estimator arima's best error=0.0047,    best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:11] {2434} INFO - iteration 50, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:11] {2594} INFO -  at 7.0s,  estimator xgb_limitdepth's best error=0.0018,   best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:11] {2434} INFO - iteration 51, current learner sarimax\n[flaml.automl: 01-21 07:54:11] {2594} INFO -  at 7.5s,  estimator sarimax's best error=0.0047,  best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:11] {2434} INFO - iteration 52, current learner xgboost\n[flaml.automl: 01-21 07:54:11] {2594} INFO -  at 7.6s,  estimator xgboost's best error=0.0242,  best estimator prophet's best error=0.0008\n[flaml.automl: 01-21 07:54:11] {2434} INFO - iteration 53, current learner prophet\n[flaml.automl: 01-21 07:54:13] {2594} INFO -  at 9.3s,  estimator prophet's best error=0.0005,  best estimator prophet's best error=0.0005\n[flaml.automl: 01-21 07:54:13] {2434} INFO - iteration 54, current learner sarimax\n[flaml.automl: 01-21 07:54:13] {2594} INFO -  at 9.4s,  estimator sarimax's best error=0.0047,  best estimator prophet's best error=0.0005\n[flaml.automl: 01-21 07:54:13] {2434} INFO - iteration 55, current learner xgb_limitdepth\n[flaml.automl: 01-21 07:54:13] {2594} INFO -  at 9.8s,  estimator xgb_limitdepth's best error=0.0018,   best estimator prophet's best error=0.0005\n[flaml.automl: 01-21 07:54:13] {2434} INFO - iteration 56, current learner xgboost\n[flaml.automl: 01-21 07:54:13] {2594} INFO -  at 9.8s,  estimator xgboost's best error=0.0242,  best estimator prophet's best error=0.0005\n[flaml.automl: 01-21 07:54:13] {2434} INFO - iteration 57, current learner lgbm\n[flaml.automl: 01-21 07:54:14] {2594} INFO -  at 9.9s,  estimator lgbm's best error=0.0017,     best estimator prophet's best error=0.0005\n[flaml.automl: 01-21 07:54:14] {2434} INFO - iteration 58, current learner rf\n[flaml.automl: 01-21 07:54:14] {2594} INFO -  at 10.0s, estimator rf's best error=0.0146,       best estimator prophet's best error=0.0005\n[flaml.automl: 01-21 07:54:14] {2824} INFO - retrain prophet for 0.6s\n[flaml.automl: 01-21 07:54:14] {2831} INFO - retrained model: <prophet.forecaster.Prophet object at 0x7fb68ea65d60>\n[flaml.automl: 01-21 07:54:14] {2210} INFO - fit succeeded\n[flaml.automl: 01-21 07:54:14] {2211} INFO - Time taken to find the best model: 9.339771270751953\n[flaml.automl: 01-21 07:54:14] {2222} WARNING - Time taken to find the best model is 93% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n")),(0,s.kt)("h4",{id:"compute-and-plot-predictions"},"Compute and plot predictions"),(0,s.kt)("p",null,"The example plotting code requires matplotlib."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"flaml_y_pred = automl.predict(X_test)\nimport matplotlib.pyplot as plt\n\nplt.plot(X_test, y_test, label='Actual level')\nplt.plot(X_test, flaml_y_pred, label='FLAML forecast')\nplt.xlabel('Date')\nplt.ylabel('CO2 Levels')\nplt.legend()\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:r(6806).Z})),(0,s.kt)("h3",{id:"multivariate-time-series-forecasting-with-exogeneous-variables"},"Multivariate Time Series (Forecasting with Exogeneous Variables)"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'import pandas as pd\n\n# pd.set_option("display.max_rows", None, "display.max_columns", None)\nmulti_df = pd.read_csv(\n    "https://raw.githubusercontent.com/srivatsan88/YouTubeLI/master/dataset/nyc_energy_consumption.csv"\n)\n\n# preprocessing data\nmulti_df["timeStamp"] = pd.to_datetime(multi_df["timeStamp"])\nmulti_df = multi_df.set_index("timeStamp")\nmulti_df = multi_df.resample("D").mean()\nmulti_df["temp"] = multi_df["temp"].fillna(method="ffill")\nmulti_df["precip"] = multi_df["precip"].fillna(method="ffill")\nmulti_df = multi_df[:-2]  # last two rows are NaN for \'demand\' column so remove them\nmulti_df = multi_df.reset_index()\n\n# Using temperature values create categorical values\n# where 1 denotes daily tempurature is above monthly average and 0 is below.\ndef get_monthly_avg(data):\n    data["month"] = data["timeStamp"].dt.month\n    data = data[["month", "temp"]].groupby("month")\n    data = data.agg({"temp": "mean"})\n    return data\n\nmonthly_avg = get_monthly_avg(multi_df).to_dict().get("temp")\n\ndef above_monthly_avg(date, temp):\n    month = date.month\n    if temp > monthly_avg.get(month):\n        return 1\n    else:\n        return 0\n\nmulti_df["temp_above_monthly_avg"] = multi_df.apply(\n    lambda x: above_monthly_avg(x["timeStamp"], x["temp"]), axis=1\n)\n\ndel multi_df["temp"], multi_df["month"]  # remove temperature column to reduce redundancy\n\n# split data into train and test\nnum_samples = multi_df.shape[0]\nmulti_time_horizon = 180\nsplit_idx = num_samples - multi_time_horizon\nmulti_train_df = multi_df[:split_idx]\nmulti_test_df = multi_df[split_idx:]\n\nmulti_X_test = multi_test_df[\n    ["timeStamp", "precip", "temp_above_monthly_avg"]\n]  # test dataframe must contain values for the regressors / multivariate variables\nmulti_y_test = multi_test_df["demand"]\n\n# initialize AutoML instance\nautoml = AutoML()\n\n# configure AutoML settings\nsettings = {\n    "time_budget": 10,  # total running time in seconds\n    "metric": "mape",  # primary metric\n    "task": "ts_forecast",  # task type\n    "log_file_name": "energy_forecast_categorical.log",  # flaml log file\n    "eval_method": "holdout",\n    "log_type": "all",\n    "label": "demand",\n}\n\n# train the model\nautoml.fit(dataframe=df, **settings, period=time_horizon)\n\n# predictions\nprint(automl.predict(multi_X_test))\n')),(0,s.kt)("h4",{id:"sample-output-2"},"Sample Output"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 15, current learner xgboost\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.2s,  estimator xgboost's best error=0.0959,  best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 16, current learner extra_tree\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.2s,  estimator extra_tree's best error=0.0961,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 17, current learner extra_tree\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.2s,  estimator extra_tree's best error=0.0961,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 18, current learner xgboost\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.2s,  estimator xgboost's best error=0.0959,  best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 19, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.3s,  estimator xgb_limitdepth's best error=0.0820,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 20, current learner xgboost\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.3s,  estimator xgboost's best error=0.0834,  best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 21, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.4s,  estimator xgb_limitdepth's best error=0.0820,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 22, current learner lgbm\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.4s,  estimator lgbm's best error=0.0925, best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 23, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.4s,  estimator xgb_limitdepth's best error=0.0820,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 24, current learner extra_tree\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.5s,  estimator extra_tree's best error=0.0922,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 25, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.5s,  estimator xgb_limitdepth's best error=0.0820,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 26, current learner rf\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.5s,  estimator rf's best error=0.0862,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 27, current learner rf\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.6s,  estimator rf's best error=0.0856,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:26] {2458} INFO - iteration 28, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:32:26] {2620} INFO -  at 6.6s,  estimator xgb_limitdepth's best error=0.0820,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:27] {2458} INFO - iteration 29, current learner sarimax\n[flaml.automl: 02-28 21:32:28] {2620} INFO -  at 7.9s,  estimator sarimax's best error=0.5313,  best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:28] {2458} INFO - iteration 30, current learner xgboost\n[flaml.automl: 02-28 21:32:28] {2620} INFO -  at 8.0s,  estimator xgboost's best error=0.0834,  best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:28] {2458} INFO - iteration 31, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:32:28] {2620} INFO -  at 8.0s,  estimator xgb_limitdepth's best error=0.0791,   best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:28] {2458} INFO - iteration 32, current learner arima\n[flaml.automl: 02-28 21:32:30] {2620} INFO -  at 10.3s, estimator arima's best error=0.5998,    best estimator prophet's best error=0.0592\n[flaml.automl: 02-28 21:32:32] {2850} INFO - retrain prophet for 2.2s\n[flaml.automl: 02-28 21:32:32] {2857} INFO - retrained model: <prophet.forecaster.Prophet object at 0x000001B1D3EE2B80>\n[flaml.automl: 02-28 21:32:32] {2234} INFO - fit succeeded\n[flaml.automl: 02-28 21:32:32] {2235} INFO - Time taken to find the best model: 4.351356506347656\n")),(0,s.kt)("h3",{id:"forecasting-discrete-variables"},"Forecasting Discrete Variables"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'from hcrystalball.utils import get_sales_data\nimport numpy as np\nfrom flaml import AutoML\n\ntime_horizon = 30\ndf = get_sales_data(n_dates=180, n_assortments=1, n_states=1, n_stores=1)\ndf = df[["Sales", "Open", "Promo", "Promo2"]]\n\n# feature engineering - create a discrete value column\n# 1 denotes above mean and 0 denotes below mean\ndf["above_mean_sales"] = np.where(df["Sales"] > df["Sales"].mean(), 1, 0)\ndf.reset_index(inplace=True)\n\n# train-test split\ndiscrete_train_df = df[:-time_horizon]\ndiscrete_test_df = df[-time_horizon:]\ndiscrete_X_train, discrete_X_test = (\n    discrete_train_df[["Date", "Open", "Promo", "Promo2"]],\n    discrete_test_df[["Date", "Open", "Promo", "Promo2"]],\n)\ndiscrete_y_train, discrete_y_test = discrete_train_df["above_mean_sales"], discrete_test_df["above_mean_sales"]\n\n# initialize AutoML instance\nautoml = AutoML()\n\n# configure the settings\nsettings = {\n    "time_budget": 15,  # total running time in seconds\n    "metric": "accuracy",  # primary metric\n    "task": "ts_forecast_classification",  # task type\n    "log_file_name": "sales_classification_forecast.log",  # flaml log file\n    "eval_method": "holdout",\n}\n\n# train the model\nautoml.fit(X_train=discrete_X_train,\n           y_train=discrete_y_train,\n           **settings,\n           period=time_horizon)\n\n# make predictions\ndiscrete_y_pred = automl.predict(discrete_X_test)\nprint("Predicted label", discrete_y_pred)\nprint("True label", discrete_y_test)\n')),(0,s.kt)("h4",{id:"sample-output-3"},"Sample Output"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"[flaml.automl: 02-28 21:53:03] {2060} INFO - task = ts_forecast_classification\n[flaml.automl: 02-28 21:53:03] {2062} INFO - Data split method: time\n[flaml.automl: 02-28 21:53:03] {2066} INFO - Evaluation method: holdout\n[flaml.automl: 02-28 21:53:03] {2147} INFO - Minimizing error metric: 1-accuracy\n[flaml.automl: 02-28 21:53:03] {2205} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 0, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2573} INFO - Estimated sufficient time budget=269s. Estimated necessary time budget=0s.\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.1s,  estimator lgbm's best error=0.2667, best estimator lgbm's best error=0.2667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 1, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.1s,  estimator lgbm's best error=0.2667, best estimator lgbm's best error=0.2667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 2, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.1s,  estimator lgbm's best error=0.1333, best estimator lgbm's best error=0.1333\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 3, current learner rf\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.2s,  estimator rf's best error=0.1333,   best estimator lgbm's best error=0.1333\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 4, current learner xgboost\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.2s,  estimator xgboost's best error=0.1333,  best estimator lgbm's best error=0.1333\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 5, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.2s,  estimator lgbm's best error=0.1333, best estimator lgbm's best error=0.1333\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 6, current learner rf\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.3s,  estimator rf's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 7, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.3s,  estimator lgbm's best error=0.0667, best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 8, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.3s,  estimator lgbm's best error=0.0667, best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 9, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.4s,  estimator lgbm's best error=0.0667, best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 10, current learner rf\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.4s,  estimator rf's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 11, current learner rf\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.4s,  estimator rf's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 12, current learner xgboost\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.5s,  estimator xgboost's best error=0.1333,  best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 13, current learner extra_tree\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.5s,  estimator extra_tree's best error=0.1333,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 14, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.5s,  estimator xgb_limitdepth's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 15, current learner xgboost\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.6s,  estimator xgboost's best error=0.0667,  best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 16, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.6s,  estimator xgb_limitdepth's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 17, current learner rf\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.6s,  estimator rf's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 18, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.7s,  estimator xgb_limitdepth's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 19, current learner lgbm\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.7s,  estimator lgbm's best error=0.0667, best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 20, current learner extra_tree\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.7s,  estimator extra_tree's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 21, current learner xgboost\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.7s,  estimator xgboost's best error=0.0667,  best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 22, current learner extra_tree\n[flaml.automl: 02-28 21:53:03] {2620} INFO -  at 0.8s,  estimator extra_tree's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:03] {2458} INFO - iteration 23, current learner rf\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 0.8s,  estimator rf's best error=0.0667,   best estimator rf's best error=0.0667\n[flaml.automl: 02-28 21:53:04] {2458} INFO - iteration 24, current learner xgboost\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 0.9s,  estimator xgboost's best error=0.0333,  best estimator xgboost's best error=0.0333\n[flaml.automl: 02-28 21:53:04] {2458} INFO - iteration 25, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 0.9s,  estimator xgb_limitdepth's best error=0.0667,   best estimator xgboost's best error=0.0333\n[flaml.automl: 02-28 21:53:04] {2458} INFO - iteration 26, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 0.9s,  estimator xgb_limitdepth's best error=0.0667,   best estimator xgboost's best error=0.0333\n[flaml.automl: 02-28 21:53:04] {2458} INFO - iteration 27, current learner xgboost\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 0.9s,  estimator xgboost's best error=0.0333,  best estimator xgboost's best error=0.0333\n[flaml.automl: 02-28 21:53:04] {2458} INFO - iteration 28, current learner extra_tree\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 1.0s,  estimator extra_tree's best error=0.0667,   best estimator xgboost's best error=0.0333\n[flaml.automl: 02-28 21:53:04] {2458} INFO - iteration 29, current learner xgb_limitdepth\n[flaml.automl: 02-28 21:53:04] {2620} INFO -  at 1.0s,  estimator xgb_limitdepth's best error=0.0667,   best estimator xgboost's best error=0.0333\n[flaml.automl: 02-28 21:53:04] {2850} INFO - retrain xgboost for 0.0s\n[flaml.automl: 02-28 21:53:04] {2857} INFO - retrained model: XGBClassifier(base_score=0.5, booster='gbtree',\n              colsample_bylevel=0.9826753651836615, colsample_bynode=1,\n              colsample_bytree=0.9725493834064914, gamma=0, gpu_id=-1,\n              grow_policy='lossguide', importance_type='gain',\n              interaction_constraints='', learning_rate=0.1665803484560213,\n              max_delta_step=0, max_depth=0, max_leaves=4,\n              min_child_weight=0.5649012460525115, missing=nan,\n              monotone_constraints='()', n_estimators=4, n_jobs=-1,\n              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n              reg_alpha=0.009638363373006869, reg_lambda=0.143703802530408,\n              scale_pos_weight=1, subsample=0.9643606787051899,\n              tree_method='hist', use_label_encoder=False,\n              validate_parameters=1, verbosity=0)\n[flaml.automl: 02-28 21:53:04] {2234} INFO - fit succeeded\n[flaml.automl: 02-28 21:53:04] {2235} INFO - Time taken to find the best model: 0.8547139167785645\n")),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://github.com/microsoft/FLAML/blob/main/notebook/automl_time_series_forecast.ipynb"},"Link to notebook")," | ",(0,s.kt)("a",{parentName:"p",href:"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/automl_time_series_forecast.ipynb"},"Open in colab")))}f.isMDXComponent=!0},6806:function(t,e,r){e.Z=r.p+"assets/images/CO2-8a52a5b6467f2f3c0b4bc0fc516d5a62.png"}}]);